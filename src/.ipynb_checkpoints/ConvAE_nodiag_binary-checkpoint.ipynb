{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import config as conf\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ConvVAE_model as cvae\n",
    "import v2_logpx_z_ConvVAE_model as pcvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = '/cavern/bihuayu/protein_DP/AE/nodiag_binary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x):\n",
    "    sz = tf.size(x['contact'])\n",
    "    edge = tf.math.sqrt(tf.cast(sz, tf.float32))\n",
    "    edge = tf.cast(edge, tf.int32)\n",
    "    \n",
    "    contact_img = x['contact']\n",
    "    \n",
    "    diag = tf.linalg.diag_part(x['contact'],k=(-1,1))\n",
    "    x['diag'] = tf.linalg.diag(diag,k=(-1,1))\n",
    "    x['contact'] = x['contact'] - x['diag']\n",
    "    \n",
    "    zero = tf.constant(0, dtype=tf.float32)\n",
    "    one = tf.constant(1, dtype=tf.float32)\n",
    "    img = tf.where(tf.not_equal(x[\"contact\"], zero), one, zero)\n",
    "    \n",
    "    img_norm = tf.expand_dims(img, -1)\n",
    "    \n",
    "    if edge > 600:\n",
    "        img_norm = tf.image.resize_with_crop_or_pad(img_norm, 600, 600)\n",
    "    elif edge < 8:\n",
    "        img_norm = tf.image.resize_with_crop_or_pad(img_norm, 8, 8)\n",
    "    elif edge % 8 != 0:\n",
    "        mod = 8 - edge % 8\n",
    "        img_norm = tf.image.resize_with_crop_or_pad(img_norm, edge+mod, edge+mod)\n",
    "        \n",
    "    x['contact'] = img_norm\n",
    "    x['diag'] = img_norm\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_BUF = 6000\n",
    "BATCH_SIZE = 1\n",
    "TEST_BUF = 1000\n",
    "\n",
    "import contact_map as cp\n",
    "data = cp.contact_map()\n",
    "\n",
    "train_norm = data.train.map(normalization)\n",
    "val_varseq_norm = data.val_varseq.map(normalization)\n",
    "val_decoy_norm = data.val_decoy.map(normalization)\n",
    "\n",
    "train_set = train_norm.shuffle(TRAIN_BUF).batch(BATCH_SIZE)\n",
    "val_varseq_set = val_varseq_norm.batch(1)\n",
    "val_decoy_set = val_decoy_norm.shuffle(TRAIN_BUF).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOrElEQVR4nO3df4hdd5nH8ffHmCa2GsxoE2abYhRC11JsKkNSyeLGdqOxivGfLhZcwhKYf+pSWaVNdmHBhYUsC+L+sSwMa9eAXTWoNSGIbRjNH4LETrepJqYx3ZptQ2YzWre0K2xM67N/3BP3djo/ztx7ftx7n88LhnPPuXPnPPfOPPN9vud8z/coIjCz0femtgMws2Y42c2ScLKbJeFkN0vCyW6WhJPdLIm+kl3SbknnJD0raX9VQZlZ9dTreXZJq4CfA7uAi8ATwH0R8bPqwjOzqry5j9duA56NiOcAJH0d2AMsmuzXaU2s5YY+dmlmS/lffsNv44oWeq6fZL8JeKFr/SKwfakXrOUGtuvuPnZpZks5GdOLPtdPsi/03+MNfQJJk8AkwFqu72N3ZtaPfg7QXQRu7lrfBFya/00RMRURExExsZo1fezOzPrRT7I/AWyR9G5J1wGfAo5WE5aZVa3nMj4iXpX0GeAxYBXwcEScqSwyM6tUP312IuK7wHcrisXMauQRdGZJONnNknCymyXhZDdLwsluloST3SwJJ7tZEk52sySc7GZJONnNkuhruOygeezSqd8//sgfbG0tDrNB5JbdLAknu1kSI1XGj1Lp7i6JVc0tu1kSTnazJJzsZkkMXZ99lPqy3e9lvmF/bzZ43LKbJeFkN0ti6Mr4US5vR/m91WmUunZ1cstuloST3SwJJ7tZEkPXZ6/a/NNfVff5lvr57l9Ww59jOcu27JIeljQn6XTXtjFJxyWdL5br6w3TzPpVpoz/CrB73rb9wHREbAGmi3UzG2CKeMMt1d/4TdJm4FhE3FasnwN2RsSspHHgRETcstzPWaex2K67+wzZ2lJ3l2ep/blUL+dkTPNy/FoLPdfrAbqNETELUCw39BqcmTWj9gN0kiaBSYC1XF/37sxsEb0m+2VJ411l/Nxi3xgRU8AUdMr4HvfXt15KwrJla5YLWpp+L6P02Q2CXsv4o8De4vFe4Eg14ZhZXcqcevsa8CPgFkkXJe0DDgK7JJ0HdhXrZjbAli3jI+K+RZ7yYXWzIZJmBF0v/b/5rynb7+9+runTVXUapfeSkcfGmyXhZDdLotQIuqoM4gg6l6a98wi3wVPHCDozGzJOdrMknOxmSaQ59baYXk+vmT+fYeOW3SwJJ7tZEunL+PlcmtqocstuloST3SyJ9GV8loknzNyymyXhZDdLwslulkT6Pvt87qfbqHLLbpaEk90siTRl/GIXuPhCmPI80cdwc8tuloST3SwJJ7tZEuknnDQbJX1NOCnpZkk/kHRW0hlJDxTbxyQdl3S+WK6vOnAzq06ZMv5V4HMR8V7gTuB+SbcC+4HpiNgCTBfrZjagytzrbRaYLR6/IukscBOwB9hZfNsh4ATwUC1RluQr2MqfOvRnlc+KDtBJ2gzcAZwENhb/CK79Q9hQeXRmVpnSyS7prcC3gM9GxMsreN2kpBlJM1e50kuMZlaBUskuaTWdRH8kIr5dbL4sabx4fhyYW+i1ETEVERMRMbGaNVXEbGY9WLbPLknAl4GzEfHFrqeOAnuBg8XySC0R9miU+p1L9a/nK/u+R+nzsXLKjI3fAfwZ8FNJp4ptf0UnyQ9L2gc8D9xbS4RmVokyR+N/CCx4kh7wCBmzITHUV71luQrLV+ZZFTw23iwJJ7tZEkNdxo9aCVu2PB+1923NcMtuloST3SwJJ7tZEkPdZx9lPr1mVXPLbpaEk90sCZfxA8qlu1XNLbtZEk52sySc7GZJuM/eoiav2qtjAgwbLm7ZzZJwspsl4ds/meeQHyF93f7JzEaDk90sCR+NHzFVX0DjC3JGh1t2sySc7GZJONnNknCfvUWDMu992Vs7D0q81ptlW3ZJayX9WNLTks5I+kKxfUzScUnni+X6+sM1s16VKeOvAHdFxO3AVmC3pDuB/cB0RGwBpot1MxtQZe71FsD/FKuri68A9gA7i+2HgBPAQ5VHaD0bxJFx7gq0p+z92VcVd3CdA45HxElgY0TMAhTLDbVFaWZ9K5XsEfFaRGwFNgHbJN1WdgeSJiXNSJq5ypUewzSzfq3o1FtEvESnXN8NXJY0DlAs5xZ5zVRETETExGrW9BetmfVs2aveJN0IXI2IlyS9BXgc+Hvgj4EXI+KgpP3AWEQ8uNTP8lVvzRrEPrvVa6mr3sqcZx8HDklaRacSOBwRxyT9CDgsaR/wPHBvZRGbWeXKHI3/CXDHAttfBNxMmw0Jj6AbYd2l+vyS3iV+Ph4bb5aEk90siZRl/FITMtQ5+UNVP7MXS73PunkCjMHglt0sCSe7WRJOdrMkPG/8Egalvz2Myh4T8GdaLc8bb2ZOdrMsUp56K8slZu8WG71X96lOW5xbdrMknOxmSTjZzZJwn916Vra/3etzVi237GZJONnNknAZb6UtNSqu19GGHmnXHLfsZkk42c2ScBlvpUvwOka/9VLuu6TvjVt2sySc7GZJONnNkvDkFVaJpfr9ozqJ5yCqZPKK4rbNT0k6VqyPSTou6XyxXF9VwGZWvZWU8Q8AZ7vW9wPTEbEFmC7WzWxAlTr1JmkT8DHg74C/LDbvAXYWjw/RuZXzQ9WGZ8OizVLap+XKKduyfwl4EPhd17aNETELUCw3VBuamVVp2WSX9HFgLiKe7GUHkiYlzUiaucqVXn6EmVWgTBm/A/iEpHuAtcA6SV8FLksaj4hZSePA3EIvjogpYAo6R+MritvMVqjM/dkPAAcAJO0EPh8Rn5b0D8Be4GCxPFJfmNVyH290+bTc4voZVHMQ2CXpPLCrWDezAbWiC2Ei4gSdo+5ExIuAR8iYDQmPoLNGNV1mZ+uy+fZPZuZkN8vCk1dYo5aaAGMlr+tlf9lK+vncspsl4WQ3S8LJbpbEyPbZPZJqOCzWp256Xxn+PtyymyXhZDdLYmTL+Axl2ajp9bRc1fsa1b8dt+xmSTjZzZJwspslMbJ9dht+TQ51zXBazi27WRJOdrMkXMbbUGizzB6V03Ju2c2ScLKbJeEy3oZOm6PfhvlIvVt2sySc7GZJONnNknCf3YZe1aflVvKaYTotV/b+7BeAV4DXgFcjYkLSGPANYDNwAfjTiPjvesI0s36tpIz/UERsjYiJYn0/MB0RW4DpYt3MBlQ/ZfweYGfx+BCde8A91Gc8Zn1pel76xfY1iCV92ZY9gMclPSlpsti2MSJmAYrlhjoCNLNqlG3Zd0TEJUkbgOOSnim7g+KfwyTAWq7vIUQzq0Kplj0iLhXLOeBRYBtwWdI4QLGcW+S1UxExERETq1lTTdRmtmLLtuySbgDeFBGvFI8/DPwtcBTYCxwslkfqDNSsF3XPS7/Yzx/EYbVlyviNwKOSrn3/v0XE9yQ9ARyWtA94Hri3vjDNrF/LJntEPAfcvsD2F4G76wjKzKrnEXSWRpO3mhpEHhtvloST3SwJJ7tZEu6zW0orGVZb9rTZoB8TcMtuloST3SwJRURjO1unsdgun5q3wbaSEnwQRsZ1OxnTvBy/1kLPuWU3S8LJbpaEj8abzbOSI/WDPmFFN7fsZkk42c2ScLKbJeE+u9kyBr0vXpZbdrMknOxmSTjZzZJwspsl4WQ3S8LJbpaEk90sCSe7WRJOdrMknOxmSZRKdklvl/RNSc9IOivpA5LGJB2XdL5Yrq87WDPrXdmW/R+B70XEH9K5FdRZYD8wHRFbgOli3cwG1LLJLmkd8EHgywAR8duIeAnYAxwqvu0Q8Ml6QjSzKpRp2d8D/BL4V0lPSfqX4tbNGyNiFqBYbqgxTjPrU5lkfzPwfuCfI+IO4DesoGSXNClpRtLMVa70GKaZ9atMsl8ELkbEyWL9m3SS/7KkcYBiObfQiyNiKiImImJiNWuqiNnMerBsskfEfwEvSLql2HQ38DPgKLC32LYXOFJLhGZWibIz1fwF8Iik64DngD+n84/isKR9wPPAvfWEaGZVKJXsEXEKmFjgKd/exWxIeASdWRJOdrMknOxmSTjZzZJwspsl4WQ3S8LJbpaEIqK5nUm/BP4TeCfwq8Z2vDjH8XqO4/UGIY6VxvCuiLhxoScaTfbf71SaiYiFBuk4DsfhOGqKwWW8WRJOdrMk2kr2qZb2O5/jeD3H8XqDEEdlMbTSZzez5rmMN0ui0WSXtFvSOUnPSmpsNlpJD0uak3S6a1vjU2FLulnSD4rpuM9IeqCNWCStlfRjSU8XcXyhjTi64llVzG94rK04JF2Q9FNJpyTNtBhHbdO2N5bsklYB/wR8FLgVuE/SrQ3t/ivA7nnb2pgK+1XgcxHxXuBO4P7iM2g6livAXRFxO7AV2C3pzhbiuOYBOtOTX9NWHB+KiK1dp7raiKO+adsjopEv4APAY13rB4ADDe5/M3C6a/0cMF48HgfONRVLVwxHgF1txgJcD/w7sL2NOIBNxR/wXcCxtn43wAXgnfO2NRoHsA74BcWxtKrjaLKMvwl4oWv9YrGtLa1OhS1pM3AHcLKNWIrS+RSdiUKPR2dC0TY+ky8BDwK/69rWRhwBPC7pSUmTLcVR67TtTSa7FtiW8lSApLcC3wI+GxEvtxFDRLwWEVvptKzbJN3WdAySPg7MRcSTTe97ATsi4v10upn3S/pgCzH0NW37cppM9ovAzV3rm4BLDe5/vlJTYVdN0mo6if5IRHy7zVgAonN3nxN0jmk0HccO4BOSLgBfB+6S9NUW4iAiLhXLOeBRYFsLcfQ1bftymkz2J4Atkt5dzFL7KTrTUbel8amwJYnObbTORsQX24pF0o2S3l48fgvwJ8AzTccREQciYlNEbKbz9/D9iPh003FIukHS2649Bj4MnG46jqh72va6D3zMO9BwD/Bz4D+Av25wv18DZoGrdP577gPeQefA0PliOdZAHH9Ep+vyE+BU8XVP07EA7wOeKuI4DfxNsb3xz6Qrpp38/wG6pj+P9wBPF19nrv1ttvQ3shWYKX433wHWVxWHR9CZJeERdGZJONnNknCymyXhZDdLwsluloST3SwJJ7tZEk52syT+D4pmxRKlrfrEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in val_varseq_set:\n",
    "    plt.imshow(x['contact'][0,:,:,0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTACT_MAP_log_norm\n",
      "Model: \"cvae\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Sequential)         multiple                  223360    \n",
      "_________________________________________________________________\n",
      "decoder (Sequential)         multiple                  370817    \n",
      "=================================================================\n",
      "Total params: 594,177\n",
      "Trainable params: 592,897\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "\n",
    "model = pcvae.CVAE(latent_dim = 50, mnist = False, units_list=[64,128,128])\n",
    "model.compile(optimizer = model.optimizer, loss = model.compute_loss, metrics = [\"accuracy\"] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation\n",
      "Epoch: 1, Test set loss: 0.0058873435482382774, time elapse for current epoch 1062.0725355148315\n",
      "orignal image\n",
      "reconstruction\n"
     ]
    }
   ],
   "source": [
    "def generate_and_display_images(model, test_input):\n",
    "    z = model.encode(test_input, False)\n",
    "    recon = model.decode(z, False)\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "        \n",
    "    for i in range(1):\n",
    "        plt.subplot(2, 1, i+1)\n",
    "        tf.print('orignal image')\n",
    "        plt.imshow(test_input[i, :, :, 0])\n",
    "        plt.axis('off')\n",
    "        tf.print('reconstruction')\n",
    "        plt.subplot(2, 1, i+2)\n",
    "        plt.imshow(recon[i, :, :, 0])\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "    plt.savefig(parent_dir + 'image_at_epoch_{:04d}.png'.format(epoch))        \n",
    "#     plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "checkpoint_path = parent_dir + \"cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    t_loss = tf.keras.metrics.Mean()\n",
    "    loss = tf.keras.metrics.Mean()\n",
    "    score = []\n",
    "    val_varseq_predict = []\n",
    "    val_varseq_label = []\n",
    "\n",
    "    start_time = time.time()\n",
    "    for train_x in train_set:\n",
    "        assert not np.any(np.isnan(train_x[\"contact\"]))\n",
    "        cost = model.compute_apply_gradients(train_x[\"contact\"], True, True)\n",
    "        t_loss(cost)\n",
    "    end_time = time.time()\n",
    "\n",
    "\n",
    "    print(\"validation\")\n",
    "    for test_x in val_varseq_set:\n",
    "        assert not np.any(np.isnan(test_x[\"contact\"]))\n",
    "        score = model.compute_loss(test_x[\"contact\"], False, True)\n",
    "        loss(score)\n",
    "        val_varseq_predict = tf.concat([val_varseq_predict, score], 0)\n",
    "        val_varseq_label = tf.concat([val_varseq_label, test_x[\"label\"]], 0)\n",
    "  \n",
    "    print('Epoch: {}, Test set loss: {}, '\n",
    "        'time elapse for current epoch {}'.format(epoch,\n",
    "                                                  loss.result(),\n",
    "                                                  end_time - start_time))\n",
    "\n",
    "    train_loss.append(t_loss.result())\n",
    "    val_loss.append(loss.result())\n",
    "    model.save_weights(checkpoint_path.format(epoch=epoch))\n",
    "    generate_and_display_images(model, test_x[\"contact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f = open(parent_dir + \"train_loss.pkl\",\"wb\")\n",
    "pickle.dump(train_loss,f)\n",
    "f.close()\n",
    "\n",
    "f = open(parent_dir + \"val_loss.pkl\",\"wb\")\n",
    "pickle.dump(val_loss,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
